{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfe5ab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abbb0f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_between( s, first, last ):\n",
    "    try:\n",
    "        start = s.index( first ) + len( first )\n",
    "        end = s.index( last, start )\n",
    "        return s[start:end]\n",
    "    except ValueError:\n",
    "        return \"\"\n",
    "    \n",
    "# source: https://stackoverflow.com/questions/3368969/find-string-between-two-substrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b04d45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(\"console_output_2.txt\", \"a\")\n",
    "# now = datetime.now()\n",
    "# current_time = now.strftime(\"%H:%M:%S\")\n",
    "# f.write(\"file open at =\" + current_time + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "969e7100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program start at 16:46:20\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"program start at\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f36f5bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "allUrl = \"http://www.nuforc.org/webreports/ndxloc.html\"\n",
    "allPage = urllib.request.urlopen(allUrl)\n",
    "allSoup = BeautifulSoup(allPage, 'html.parser')\n",
    "\n",
    "states = {\n",
    "    'AK': 'ALASKA',\n",
    "    'AL': 'ALABAMA',\n",
    "    'AR': 'ARKANSAS',\n",
    "    'AZ': 'ARIZONA',\n",
    "    'CA': 'CALIFORNIA',\n",
    "    'CO': 'COLORADO',\n",
    "    'CT': 'CONNECTICUT',\n",
    "    'DC': 'DISTRICT OF COLUMBIA',\n",
    "    'DE': 'DELAWARE',\n",
    "    'FL': 'FLORIDA',\n",
    "    'GA': 'GEORGIA',\n",
    "    'HI': 'HAWAII',\n",
    "    'IA': 'IOWA',\n",
    "    'ID': 'IDAHO',\n",
    "    'IL': 'ILLINOIS',\n",
    "    'IN': 'INDIANA',\n",
    "    'KS': 'KANSAS',\n",
    "    'KY': 'KENTUCKY',\n",
    "    'LA': 'LOUISIANA',\n",
    "    'MA': 'MASSACHUSETTS',\n",
    "    'MD': 'MARYLAND',\n",
    "    'ME': 'MAINE',\n",
    "    'MI': 'MICHIGAN',\n",
    "    'MN': 'MINNESOTA',\n",
    "    'MO': 'MISSOURI',\n",
    "    'MS': 'MISSISSIPPI',\n",
    "    'MT': 'MONTANA',\n",
    "    'NC': 'NORTH CAROLINA',\n",
    "    'ND': 'NORTH DAKOTA',\n",
    "    'NE': 'NEBRASKA',\n",
    "    'NH': 'NEW HAMPSHIRE',\n",
    "    'NJ': 'NEW JERSEY',\n",
    "    'NM': 'NEW MEXICO',\n",
    "    'NV': 'NEVADA',\n",
    "    'NY': 'NEW YORK',\n",
    "    'OH': 'OHIO',\n",
    "    'OK': 'OKLAHOMA',\n",
    "    'OR': 'OREGON',\n",
    "    'PA': 'PENNSYLVANIA',\n",
    "    'RI': 'RHODE ISLAND',\n",
    "    'SC': 'SOUTH CAROLINA',\n",
    "    'SD': 'SOUTH DAKOTA',\n",
    "    'TN': 'TENNESSEE',\n",
    "    'TX': 'TEXAS',\n",
    "    'UT': 'UTAH',\n",
    "    'VA': 'VIRGINIA',\n",
    "    'VT': 'VERMONT',\n",
    "    'WA': 'WASHINGTON',\n",
    "    'WI': 'WISCONSIN',\n",
    "    'WV': 'WEST VIRGINIA',\n",
    "    'WY': 'WYOMING'\n",
    "}\n",
    "\n",
    "# thanks to https://gist.github.com/JeffPaine/3083347\n",
    "\n",
    "table = allSoup.find(\"table\")\n",
    "\n",
    "stateLinks = []\n",
    "for link in table.find_all(\"a\"):\n",
    "    if link.get_text() in states.values():\n",
    "        stateLinks.append(link['href'])\n",
    "\n",
    "reportLinks = []\n",
    "for state in stateLinks:\n",
    "    stateUrl = 'http://www.nuforc.org/webreports/' + state\n",
    "    statePage = urllib.request.urlopen(stateUrl)\n",
    "    stateSoup = BeautifulSoup(statePage, 'html.parser')\n",
    "    stateTable = stateSoup.find(\"tbody\")\n",
    "    for x in stateTable.find_all(\"tr\"):\n",
    "        link = x.find(\"a\")['href']\n",
    "        reportLinks.append('http://www.nuforc.org/webreports/' + link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d3f88ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122754"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reportLinks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7402794d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "going into loop at  16:51:03\n",
      "counter at  0  at  16:51:03\n",
      "counter at  1000  at  16:52:37\n",
      "counter at  2000  at  16:54:10\n",
      "counter at  3000  at  16:55:49\n",
      "counter at  4000  at  16:57:25\n",
      "counter at  5000  at  16:59:05\n",
      "counter at  6000  at  17:00:37\n",
      "counter at  7000  at  17:02:15\n",
      "counter at  8000  at  17:03:51\n",
      "counter at  9000  at  17:05:29\n",
      "counter at  10000  at  17:07:07\n",
      "counter at  11000  at  17:08:41\n",
      "counter at  12000  at  17:10:17\n",
      "counter at  13000  at  17:11:56\n",
      "counter at  14000  at  17:13:35\n",
      "counter at  15000  at  17:15:21\n",
      "counter at  16000  at  17:16:59\n",
      "counter at  17000  at  17:18:38\n",
      "counter at  18000  at  17:20:08\n",
      "counter at  19000  at  17:21:41\n",
      "counter at  20000  at  17:23:13\n",
      "counter at  21000  at  17:24:46\n",
      "counter at  22000  at  17:26:21\n",
      "counter at  23000  at  17:28:00\n",
      "counter at  24000  at  17:29:37\n",
      "counter at  25000  at  17:31:14\n",
      "counter at  26000  at  17:32:49\n",
      "counter at  27000  at  17:34:23\n",
      "counter at  28000  at  17:36:00\n",
      "counter at  29000  at  17:37:40\n",
      "counter at  30000  at  17:39:17\n",
      "counter at  31000  at  17:40:51\n",
      "counter at  32000  at  17:42:25\n",
      "counter at  33000  at  17:44:01\n",
      "counter at  34000  at  17:45:35\n",
      "counter at  35000  at  17:47:04\n",
      "counter at  36000  at  17:48:42\n",
      "counter at  37000  at  17:50:38\n",
      "counter at  38000  at  17:52:24\n",
      "counter at  39000  at  17:53:58\n",
      "counter at  40000  at  17:55:31\n",
      "counter at  41000  at  17:57:03\n",
      "counter at  42000  at  17:58:34\n",
      "counter at  43000  at  18:00:07\n",
      "counter at  44000  at  18:01:35\n",
      "counter at  45000  at  18:03:05\n",
      "counter at  46000  at  18:04:37\n",
      "counter at  47000  at  18:06:09\n",
      "counter at  48000  at  18:07:40\n",
      "counter at  49000  at  18:09:11\n",
      "counter at  50000  at  18:10:45\n",
      "counter at  51000  at  18:12:15\n",
      "counter at  52000  at  18:13:53\n",
      "counter at  53000  at  18:15:24\n",
      "counter at  54000  at  18:16:55\n",
      "counter at  55000  at  18:18:26\n",
      "counter at  56000  at  18:19:55\n",
      "counter at  57000  at  18:21:25\n",
      "counter at  58000  at  18:22:58\n",
      "counter at  59000  at  18:24:30\n",
      "counter at  60000  at  18:26:00\n",
      "counter at  61000  at  18:27:32\n",
      "counter at  62000  at  18:29:03\n",
      "counter at  63000  at  18:30:34\n",
      "counter at  64000  at  18:32:05\n",
      "counter at  65000  at  18:33:37\n",
      "counter at  66000  at  18:35:07\n",
      "counter at  67000  at  18:36:39\n",
      "counter at  68000  at  18:38:10\n",
      "counter at  69000  at  18:39:40\n",
      "counter at  70000  at  18:41:12\n",
      "counter at  71000  at  18:42:45\n",
      "counter at  72000  at  18:44:17\n",
      "counter at  73000  at  18:45:48\n",
      "counter at  74000  at  18:47:22\n",
      "counter at  75000  at  18:48:57\n",
      "counter at  76000  at  18:50:27\n",
      "counter at  77000  at  18:52:05\n",
      "counter at  78000  at  18:53:43\n",
      "counter at  79000  at  18:55:14\n",
      "counter at  80000  at  18:56:49\n",
      "counter at  81000  at  18:58:23\n",
      "counter at  82000  at  18:59:59\n",
      "counter at  83000  at  19:01:35\n",
      "counter at  84000  at  19:03:11\n",
      "counter at  85000  at  19:04:42\n",
      "counter at  86000  at  19:06:14\n",
      "counter at  87000  at  19:07:44\n",
      "counter at  88000  at  19:09:15\n",
      "counter at  89000  at  19:10:46\n",
      "counter at  90000  at  19:12:20\n",
      "counter at  91000  at  19:13:51\n",
      "counter at  92000  at  19:15:24\n",
      "counter at  93000  at  19:16:55\n",
      "counter at  94000  at  19:18:25\n",
      "counter at  95000  at  19:19:57\n",
      "counter at  96000  at  19:21:30\n",
      "counter at  97000  at  19:23:01\n",
      "counter at  98000  at  19:24:36\n",
      "counter at  99000  at  19:26:07\n",
      "counter at  100000  at  19:27:39\n",
      "counter at  101000  at  19:29:09\n",
      "counter at  102000  at  19:30:40\n",
      "counter at  103000  at  19:32:18\n",
      "counter at  104000  at  19:33:57\n",
      "counter at  105000  at  19:35:32\n",
      "counter at  106000  at  19:37:06\n",
      "counter at  107000  at  19:38:33\n",
      "counter at  108000  at  19:40:08\n",
      "counter at  109000  at  19:41:40\n",
      "counter at  110000  at  19:43:13\n",
      "counter at  111000  at  19:44:44\n",
      "counter at  112000  at  19:46:16\n",
      "counter at  113000  at  19:47:52\n",
      "counter at  114000  at  19:49:35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter at  115000  at  19:51:10\n",
      "counter at  116000  at  19:52:46\n",
      "counter at  117000  at  19:54:21\n",
      "counter at  118000  at  19:55:50\n",
      "counter at  119000  at  19:57:20\n",
      "counter at  120000  at  19:58:51\n",
      "counter at  121000  at  20:00:28\n",
      "counter at  122000  at  20:02:12\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "now = datetime.now()\n",
    "loop_start = now\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"going into loop at \", current_time)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for link in reportLinks:\n",
    "    reportPage = urllib.request.urlopen(link)\n",
    "    reportSoup = BeautifulSoup(reportPage, 'html.parser')\n",
    "    report = reportSoup.find(\"tbody\").find_all(\"td\")\n",
    "    text = list(report[0].stripped_strings)\n",
    "    textString = \" \".join(text)\n",
    "    occured = \"\"\n",
    "    reported = \"\"\n",
    "    posted = \"\"\n",
    "    town = \"\"\n",
    "    state = \"\"\n",
    "    shape = \"\"\n",
    "    duration = \"\"\n",
    "    characteristics = \"\"\n",
    "    \n",
    "    for line in text:\n",
    "        if \"Occurred\" in line:\n",
    "            occurred = find_between(line, \":\", \"(\").strip()\n",
    "        if \"Reported\" in line:\n",
    "            reported_date = find_between(line, \": \", \" \").strip()\n",
    "            if \"AM\" in line:\n",
    "                reported_time = line.split(\"AM\")[1].strip()\n",
    "            if \"PM\" in line:\n",
    "                reported_time = line.split(\"PM\")[1].strip()\n",
    "            reported = reported_date + \" \" + reported_time\n",
    "        if \"Posted\" in line:\n",
    "            posted = line.split(\":\")[1].strip()\n",
    "        if \"Location\" in line:\n",
    "            location = line.split(\":\")[1].strip()\n",
    "            local = location.split(\", \")\n",
    "            town = local[0].strip()\n",
    "            if len(local) > 1:\n",
    "                state = local[1].strip()\n",
    "        if \"Shape\" in line:\n",
    "            shape = line.split(\":\")[1].strip()\n",
    "        if \"Duration\" in line:\n",
    "            duration = line.split(\":\")[1].strip()\n",
    "        if \"Characteristic\" in line:\n",
    "            characteristics = line.split(\":\")[1].strip()\n",
    "      \n",
    "    summary = report[1].get_text().strip()\n",
    "    \n",
    "    img_urls = []\n",
    "    img_links = reportSoup.find_all(\"img\", {\"class\": \"ufopic\"})\n",
    "    for i in img_links: \n",
    "        img_urls.append(i[\"src\"])\n",
    "    \n",
    "    reportRow = [link, occurred, reported, posted, town, state, \"USA\", shape, \n",
    "                 duration, characteristics, summary, img_urls]\n",
    "    rows.append(reportRow)\n",
    "    \n",
    "    if counter % 1000 == 0:\n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H:%M:%S\")\n",
    "        print(\"counter at \", counter, \" at \", current_time)\n",
    "    counter+= 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dbceed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop done at 20:08:40\n",
      "time lapsed:  16:51:03 2022-05-24 20:08:40.438439\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "loop_end = now\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"loop done at\", current_time)\n",
    "\n",
    "print(\"time lapsed: \", loop_start, loop_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56c65059",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rows, \n",
    "             columns=[\"Link\", \"Occurred\", \"Reported\", \"Posted\", \"City\", \"State\", \n",
    "                      \"Country\", \"Shape\", \"Duration\", \"Characteristics\", \"Summary\", \"Images\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47335e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../big-ufo-data/nuforcData_2022.csv')\n",
    "df.to_json('../big-ufo-data/nuforcData_2022.json', orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c7074f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
